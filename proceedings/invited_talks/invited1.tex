In the age of Large Language Models, we can no longer be sure that the test data was not observed in training. 
This talk discusses the main approaches to studying generalization, and presents a new framework for working with controlled test-train splits across linguistically annotated data at scale.
